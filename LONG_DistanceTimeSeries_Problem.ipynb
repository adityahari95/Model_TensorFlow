{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LONG DistanceTimeSeries Problem",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEE7AYwYNVQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow  as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Input,Dense,SimpleRNN, GRU,LSTM,Flatten,GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpeH9oiMWMOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the dataset\n",
        "#this is a nonlinear And long distance dataset\n",
        "\n",
        "T=10\n",
        "D=1\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "def get_label(x, i1,i2, i3):\n",
        "  #x=sequence\n",
        "  if x[i1] < 0 and x[i2] < 0 and x[i3] < 0:\n",
        "    return 1\n",
        "  if x[i1] < 0 and x[i2] > 0 and x[i3] > 0:\n",
        "    return 1\n",
        "  if x[i1] > 0 and x[i2] < 0 and x[i3] > 0:\n",
        "    return 1\n",
        "  if x[i1] > 0 and x[i2] > 0 and x[i3] < 0:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "for t in range(5000):\n",
        "  x= np.random.randn(T)\n",
        "  X.append(x)\n",
        "  y= get_label(x,-1,-2,-3) #Short Distance\n",
        "# y= get_label(x,0,1,2) #Long Distance\n",
        "  Y.append(y)\n",
        "\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)\n",
        "N= len(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ScW5dT452E5",
        "colab_type": "code",
        "outputId": "d8271b95-72fe-49d6-9e52-adf4ef925508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#linear model = it is a classification now\n",
        "\n",
        "i= Input(shape=(T,))\n",
        "x= Dense(1,activation= 'sigmoid')(i)\n",
        "model= Model(i,x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer= Adam(lr= 0.01),\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "#train the model\n",
        "r= model.fit(\n",
        "    X,Y,epochs=100,validation_split=0.5,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.7753 - accuracy: 0.5136 - val_loss: 0.7114 - val_accuracy: 0.5080\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5048 - val_loss: 0.6983 - val_accuracy: 0.4800\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5052 - val_loss: 0.6975 - val_accuracy: 0.4680\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6986 - val_accuracy: 0.4664\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6986 - val_accuracy: 0.4752\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5128 - val_loss: 0.6988 - val_accuracy: 0.4688\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5052 - val_loss: 0.6984 - val_accuracy: 0.4768\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5044 - val_loss: 0.6975 - val_accuracy: 0.4648\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5120 - val_loss: 0.6963 - val_accuracy: 0.4712\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5024 - val_loss: 0.6992 - val_accuracy: 0.4720\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.5092 - val_loss: 0.6968 - val_accuracy: 0.4768\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.4968 - val_loss: 0.6964 - val_accuracy: 0.4832\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5020 - val_loss: 0.6990 - val_accuracy: 0.4700\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5092 - val_loss: 0.6976 - val_accuracy: 0.4812\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.4964 - val_loss: 0.6980 - val_accuracy: 0.4768\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5020 - val_loss: 0.6989 - val_accuracy: 0.4812\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.4752\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5024 - val_loss: 0.6975 - val_accuracy: 0.4704\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5216 - val_loss: 0.6980 - val_accuracy: 0.4768\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.5024 - val_loss: 0.6990 - val_accuracy: 0.4740\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.4988 - val_loss: 0.6976 - val_accuracy: 0.4824\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5160 - val_loss: 0.6995 - val_accuracy: 0.4644\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.4968 - val_loss: 0.6957 - val_accuracy: 0.4720\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5084 - val_loss: 0.6983 - val_accuracy: 0.4732\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.4916 - val_loss: 0.6988 - val_accuracy: 0.4672\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.4996 - val_loss: 0.6977 - val_accuracy: 0.4652\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5132 - val_loss: 0.6991 - val_accuracy: 0.4736\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5132 - val_loss: 0.6978 - val_accuracy: 0.4684\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5128 - val_loss: 0.6964 - val_accuracy: 0.4784\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5060 - val_loss: 0.6978 - val_accuracy: 0.4828\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.4952 - val_loss: 0.6989 - val_accuracy: 0.4792\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5060 - val_loss: 0.6980 - val_accuracy: 0.4780\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5124 - val_loss: 0.6982 - val_accuracy: 0.4708\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000 - val_loss: 0.6989 - val_accuracy: 0.4704\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.4992 - val_loss: 0.6994 - val_accuracy: 0.4660\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5144 - val_loss: 0.6962 - val_accuracy: 0.4772\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5060 - val_loss: 0.6966 - val_accuracy: 0.4792\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.4904 - val_loss: 0.6975 - val_accuracy: 0.4700\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5168 - val_loss: 0.6991 - val_accuracy: 0.4724\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6952 - accuracy: 0.5084 - val_loss: 0.7006 - val_accuracy: 0.4724\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.4976 - val_loss: 0.6992 - val_accuracy: 0.4688\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5044 - val_loss: 0.6982 - val_accuracy: 0.4760\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5076 - val_loss: 0.6967 - val_accuracy: 0.4728\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.4980 - val_loss: 0.6976 - val_accuracy: 0.4916\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.4968 - val_loss: 0.6998 - val_accuracy: 0.4664\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.6989 - val_accuracy: 0.4736\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5092 - val_loss: 0.6982 - val_accuracy: 0.4668\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5116 - val_loss: 0.6976 - val_accuracy: 0.4840\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5040 - val_loss: 0.6968 - val_accuracy: 0.4780\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.4996 - val_loss: 0.6958 - val_accuracy: 0.4796\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6976 - val_accuracy: 0.4736\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5100 - val_loss: 0.6981 - val_accuracy: 0.4684\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5148 - val_loss: 0.6969 - val_accuracy: 0.4712\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5028 - val_loss: 0.6969 - val_accuracy: 0.4764\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5076 - val_loss: 0.6979 - val_accuracy: 0.4716\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5164 - val_loss: 0.6965 - val_accuracy: 0.4760\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6989 - val_accuracy: 0.4712\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5048 - val_loss: 0.6969 - val_accuracy: 0.4900\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5096 - val_loss: 0.6983 - val_accuracy: 0.4780\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5072 - val_loss: 0.6965 - val_accuracy: 0.4708\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5104 - val_loss: 0.6978 - val_accuracy: 0.4704\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5120 - val_loss: 0.6980 - val_accuracy: 0.4716\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5052 - val_loss: 0.6981 - val_accuracy: 0.4800\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5052 - val_loss: 0.6979 - val_accuracy: 0.4804\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6958 - accuracy: 0.5088 - val_loss: 0.6982 - val_accuracy: 0.4760\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.5004 - val_loss: 0.6960 - val_accuracy: 0.4880\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.4988 - val_loss: 0.6965 - val_accuracy: 0.4696\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5104 - val_loss: 0.6975 - val_accuracy: 0.4756\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.4924 - val_loss: 0.6990 - val_accuracy: 0.4684\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6952 - accuracy: 0.4988 - val_loss: 0.6988 - val_accuracy: 0.4824\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.4928 - val_loss: 0.6994 - val_accuracy: 0.4828\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.4980 - val_loss: 0.6970 - val_accuracy: 0.4748\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5052 - val_loss: 0.6967 - val_accuracy: 0.4792\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5072 - val_loss: 0.6973 - val_accuracy: 0.4672\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5120 - val_loss: 0.6969 - val_accuracy: 0.4704\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6975 - val_accuracy: 0.4900\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5032 - val_loss: 0.6989 - val_accuracy: 0.4756\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5068 - val_loss: 0.7012 - val_accuracy: 0.4672\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5052 - val_loss: 0.6958 - val_accuracy: 0.4784\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5096 - val_loss: 0.6977 - val_accuracy: 0.4748\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5060 - val_loss: 0.6990 - val_accuracy: 0.4688\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5088 - val_loss: 0.6970 - val_accuracy: 0.4716\n",
            "Epoch 83/100\n",
            "54/79 [===================>..........] - ETA: 0s - loss: 0.6965 - accuracy: 0.4988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2be4f7a3205d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m r= model.fit(\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m     \"\"\"Executes the function, filtering arguments from the Python function.\n\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZvstyVdCFVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ0hw1qaCnBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['accuracy'],label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'],label='val_accur')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT8YbHZjCyV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now using Simple RNN\n",
        "\n",
        "inputs= np.expand_dims(X,-1)\n",
        "\n",
        "#make the RNN\n",
        "i= Input(shape=(T,D))\n",
        "\n",
        "#method 1\n",
        "\n",
        "#x= LSTM(5)(i)\n",
        "x= SimpleRNN(5)(i)\n",
        "#x= GRU(5)(i)\n",
        "\n",
        "#method 2\n",
        "#x= LSTM(5, return_sequence=True)(i)\n",
        "#x= GlobalMaxPool1D()(x)\n",
        "\n",
        "x= Dense(1,activation= 'sigmoid')(x)\n",
        "model= Model(i,x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              #optimizer='rmsprop',\n",
        "              #optimizer='adam',\n",
        "              optimizer= Adam(lr= 0.01),\n",
        "              #optimizer= SGD(lr= 0.01,momentum=0.9),\n",
        "              metrics=['accuracy'],\n",
        "              )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkZoivtMEJsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train the model RNN\n",
        "r= model.fit(\n",
        "    inputs,Y,\n",
        "    epochs=200,\n",
        "    validation_split=0.5,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5ZRaC7HEYll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl6VqO4PE0Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['accuracy'],label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'],label='val_accur')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpcJpwWwE6H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing it to Long Distance\n",
        "\n",
        "T=10\n",
        "D=1\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for t in range(5000):\n",
        "  x= np.random.randn(T)\n",
        "  X.append(x)\n",
        "  y= get_label(x,0,1,2) #Long Distance\n",
        "  Y.append(y)\n",
        "\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)\n",
        "N= len(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH6ulcRTF4hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now using Simple RNN\n",
        "\n",
        "inputs= np.expand_dims(X,-1)\n",
        "\n",
        "#make the RNN\n",
        "i= Input(shape=(T,D))\n",
        "\n",
        "#method 1\n",
        "\n",
        "#x= LSTM(5)(i)\n",
        "x= SimpleRNN(5)(i)\n",
        "#x= GRU(5)(i)\n",
        "\n",
        "#method 2\n",
        "#x= LSTM(5, return_sequence=True)(i)\n",
        "#x= GlobalMaxPool1D()(x)\n",
        "\n",
        "x= Dense(1,activation= 'sigmoid')(x)\n",
        "model= Model(i,x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              #optimizer='rmsprop',\n",
        "              #optimizer='adam',\n",
        "              optimizer= Adam(lr= 0.01),\n",
        "              #optimizer= SGD(lr= 0.01,momentum=0.9),\n",
        "              metrics=['accuracy'],\n",
        "              )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R62La3ZGJrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train the model RNN\n",
        "r= model.fit(\n",
        "    inputs,Y,\n",
        "    epochs=200,\n",
        "    validation_split=0.5,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwJawx5OGQFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QnQzZgqGowk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['accuracy'],label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'],label='val_accur')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzCwh06TGu5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now using LSTM\n",
        "\n",
        "inputs= np.expand_dims(X,-1)\n",
        "\n",
        "#make the RNN\n",
        "i= Input(shape=(T,D))\n",
        "\n",
        "#method 1\n",
        "\n",
        "x= LSTM(5)(i)\n",
        "#x= SimpleRNN(5)(i)\n",
        "#x= GRU(5)(i)\n",
        "\n",
        "#method 2\n",
        "#x= LSTM(5, return_sequence=True)(i)\n",
        "#x= GlobalMaxPool1D()(x)\n",
        "\n",
        "x= Dense(1,activation= 'sigmoid')(x)\n",
        "model= Model(i,x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              #optimizer='rmsprop',\n",
        "              #optimizer='adam',\n",
        "              optimizer= Adam(lr= 0.01),\n",
        "              #optimizer= SGD(lr= 0.01,momentum=0.9),\n",
        "              metrics=['accuracy'],\n",
        "   \n",
        "              )\n",
        "\n",
        "#train the model RNN\n",
        "r= model.fit(\n",
        "    inputs,Y,\n",
        "    epochs=200,\n",
        "    validation_split=0.5,\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNmqysF-H1cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['loss'],label='loss')\n",
        "plt.plot(r.history['val_loss'],label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP82feimJOhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['accuracy'],label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'],label='val_accur')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYpalqZFJSa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing it to Long Distance\n",
        "\n",
        "T=30\n",
        "D=1\n",
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "for t in range(5000):\n",
        "  x= np.random.randn(T)\n",
        "  X.append(x)\n",
        "  y= get_label(x,0,1,2) #Long Distance\n",
        "  Y.append(y)\n",
        "\n",
        "X= np.array(X)\n",
        "Y= np.array(Y)\n",
        "N= len(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCuImw_ELtOh",
        "colab_type": "code",
        "outputId": "b2a427e7-db49-4a2a-eb0a-c11f2c25f461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Now using LSTM with Global Max Pooling\n",
        "\n",
        "inputs= np.expand_dims(X,-1)\n",
        "\n",
        "#make the RNN\n",
        "i= Input(shape=(T,D))\n",
        "\n",
        "# #method 1\n",
        "\n",
        "# x= LSTM(5)(i)\n",
        "# #x= SimpleRNN(5)(i)\n",
        "# #x= GRU(5)(i)\n",
        "\n",
        "#method 2\n",
        "\n",
        "x= LSTM(5, return_sequences=True)(i)\n",
        "x= GlobalMaxPool1D()(x)\n",
        "\n",
        "x= Dense(1,activation= 'sigmoid')(x)\n",
        "model= Model(i,x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              #optimizer='rmsprop',\n",
        "              #optimizer='adam',\n",
        "              optimizer= Adam(lr= 0.01),\n",
        "              #optimizer= SGD(lr= 0.01,momentum=0.9),\n",
        "              metrics=['accuracy'],\n",
        "   \n",
        "              )\n",
        "\n",
        "#train the model RNN\n",
        "r= model.fit(\n",
        "    inputs,Y,\n",
        "    epochs=100,\n",
        "    validation_split=0.5,\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 0.6956 - accuracy: 0.4996 - val_loss: 0.6938 - val_accuracy: 0.4920\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6941 - accuracy: 0.4900 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6928 - accuracy: 0.5064 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6924 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5296\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6916 - accuracy: 0.5252 - val_loss: 0.6919 - val_accuracy: 0.5308\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6918 - accuracy: 0.5244 - val_loss: 0.6932 - val_accuracy: 0.5124\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6943 - val_accuracy: 0.5252\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.5276 - val_loss: 0.6843 - val_accuracy: 0.5376\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6918 - accuracy: 0.5272 - val_loss: 0.6887 - val_accuracy: 0.5480\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6854 - accuracy: 0.5532 - val_loss: 0.6814 - val_accuracy: 0.5256\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6767 - accuracy: 0.5508 - val_loss: 0.6732 - val_accuracy: 0.5644\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6904 - accuracy: 0.5200 - val_loss: 0.6942 - val_accuracy: 0.5016\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6917 - accuracy: 0.5268 - val_loss: 0.6916 - val_accuracy: 0.5108\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6900 - accuracy: 0.5276 - val_loss: 0.6900 - val_accuracy: 0.5232\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6873 - accuracy: 0.5468 - val_loss: 0.6856 - val_accuracy: 0.5428\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6792 - accuracy: 0.5528 - val_loss: 0.6699 - val_accuracy: 0.5808\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.6567 - accuracy: 0.6064 - val_loss: 0.6345 - val_accuracy: 0.6076\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.6245 - accuracy: 0.6472 - val_loss: 0.6103 - val_accuracy: 0.6492\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.5905 - accuracy: 0.6664 - val_loss: 0.5590 - val_accuracy: 0.7044\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.5561 - accuracy: 0.7148 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.5200 - accuracy: 0.7380 - val_loss: 0.5056 - val_accuracy: 0.7716\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4946 - accuracy: 0.7724 - val_loss: 0.4822 - val_accuracy: 0.8016\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4694 - accuracy: 0.8044 - val_loss: 0.4444 - val_accuracy: 0.8160\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4406 - accuracy: 0.8088 - val_loss: 0.4246 - val_accuracy: 0.8232\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.4168 - accuracy: 0.8220 - val_loss: 0.3937 - val_accuracy: 0.8380\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3900 - accuracy: 0.8364 - val_loss: 0.3752 - val_accuracy: 0.8448\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.4451 - accuracy: 0.8372 - val_loss: 0.4797 - val_accuracy: 0.8276\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3982 - accuracy: 0.8460 - val_loss: 0.3593 - val_accuracy: 0.8588\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3483 - accuracy: 0.8736 - val_loss: 0.3424 - val_accuracy: 0.8704\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3508 - accuracy: 0.8716 - val_loss: 0.3376 - val_accuracy: 0.8644\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.3198 - accuracy: 0.8864 - val_loss: 0.3076 - val_accuracy: 0.8816\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.3075 - accuracy: 0.8872 - val_loss: 0.2997 - val_accuracy: 0.8864\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.2932 - accuracy: 0.8968 - val_loss: 0.2845 - val_accuracy: 0.8936\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.2815 - accuracy: 0.9012 - val_loss: 0.2565 - val_accuracy: 0.9164\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.2523 - accuracy: 0.9180 - val_loss: 0.2300 - val_accuracy: 0.9296\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.2484 - accuracy: 0.9128 - val_loss: 0.2456 - val_accuracy: 0.9116\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.2257 - accuracy: 0.9332 - val_loss: 0.2121 - val_accuracy: 0.9272\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.2003 - accuracy: 0.9408 - val_loss: 0.1854 - val_accuracy: 0.9388\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1839 - accuracy: 0.9432 - val_loss: 0.1799 - val_accuracy: 0.9392\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1780 - accuracy: 0.9420 - val_loss: 0.1614 - val_accuracy: 0.9456\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1591 - accuracy: 0.9540 - val_loss: 0.1489 - val_accuracy: 0.9544\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1482 - accuracy: 0.9584 - val_loss: 0.1462 - val_accuracy: 0.9588\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.9644 - val_loss: 0.1393 - val_accuracy: 0.9584\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1332 - accuracy: 0.9628 - val_loss: 0.1321 - val_accuracy: 0.9640\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1294 - accuracy: 0.9628 - val_loss: 0.1345 - val_accuracy: 0.9616\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1380 - accuracy: 0.9620 - val_loss: 0.1286 - val_accuracy: 0.9588\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1270 - accuracy: 0.9656 - val_loss: 0.1262 - val_accuracy: 0.9612\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1526 - accuracy: 0.9568 - val_loss: 0.1426 - val_accuracy: 0.9472\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1355 - accuracy: 0.9616 - val_loss: 0.1190 - val_accuracy: 0.9676\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1113 - accuracy: 0.9736 - val_loss: 0.1133 - val_accuracy: 0.9716\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1047 - accuracy: 0.9744 - val_loss: 0.1068 - val_accuracy: 0.9708\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0991 - accuracy: 0.9736 - val_loss: 0.1057 - val_accuracy: 0.9700\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0954 - accuracy: 0.9780 - val_loss: 0.1055 - val_accuracy: 0.9664\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0928 - accuracy: 0.9768 - val_loss: 0.1024 - val_accuracy: 0.9708\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0901 - accuracy: 0.9796 - val_loss: 0.0970 - val_accuracy: 0.9716\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0874 - accuracy: 0.9784 - val_loss: 0.0948 - val_accuracy: 0.9704\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0840 - accuracy: 0.9780 - val_loss: 0.0898 - val_accuracy: 0.9732\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0781 - accuracy: 0.9824 - val_loss: 0.0871 - val_accuracy: 0.9740\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0802 - accuracy: 0.9808 - val_loss: 0.0880 - val_accuracy: 0.9736\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9848 - val_loss: 0.0834 - val_accuracy: 0.9756\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0786 - accuracy: 0.9780 - val_loss: 0.0831 - val_accuracy: 0.9732\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0715 - accuracy: 0.9796 - val_loss: 0.0859 - val_accuracy: 0.9716\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0689 - accuracy: 0.9844 - val_loss: 0.0840 - val_accuracy: 0.9732\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0670 - accuracy: 0.9844 - val_loss: 0.0755 - val_accuracy: 0.9744\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0646 - accuracy: 0.9844 - val_loss: 0.0770 - val_accuracy: 0.9752\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0639 - accuracy: 0.9832 - val_loss: 0.0786 - val_accuracy: 0.9736\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0650 - accuracy: 0.9808 - val_loss: 0.0717 - val_accuracy: 0.9792\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0609 - accuracy: 0.9852 - val_loss: 0.0755 - val_accuracy: 0.9740\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0597 - accuracy: 0.9848 - val_loss: 0.0690 - val_accuracy: 0.9792\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0560 - accuracy: 0.9860 - val_loss: 0.0710 - val_accuracy: 0.9740\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0556 - accuracy: 0.9852 - val_loss: 0.0691 - val_accuracy: 0.9792\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0527 - accuracy: 0.9876 - val_loss: 0.0714 - val_accuracy: 0.9752\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9892 - val_loss: 0.0658 - val_accuracy: 0.9772\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0536 - accuracy: 0.9876 - val_loss: 0.0700 - val_accuracy: 0.9744\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0531 - accuracy: 0.9860 - val_loss: 0.0663 - val_accuracy: 0.9780\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.0492 - accuracy: 0.9868 - val_loss: 0.0731 - val_accuracy: 0.9732\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0526 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9740\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0488 - accuracy: 0.9864 - val_loss: 0.0664 - val_accuracy: 0.9800\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0528 - accuracy: 0.9856 - val_loss: 0.0595 - val_accuracy: 0.9792\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0443 - accuracy: 0.9916 - val_loss: 0.0701 - val_accuracy: 0.9744\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.0690 - val_accuracy: 0.9748\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0453 - accuracy: 0.9900 - val_loss: 0.0580 - val_accuracy: 0.9804\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.0617 - val_accuracy: 0.9776\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0419 - accuracy: 0.9892 - val_loss: 0.0573 - val_accuracy: 0.9804\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0423 - accuracy: 0.9896 - val_loss: 0.0648 - val_accuracy: 0.9788\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.0643 - val_accuracy: 0.9748\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0423 - accuracy: 0.9876 - val_loss: 0.0608 - val_accuracy: 0.9792\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.0552 - val_accuracy: 0.9808\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0382 - accuracy: 0.9904 - val_loss: 0.0600 - val_accuracy: 0.9812\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 0.0572 - val_accuracy: 0.9780\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 0.0597 - val_accuracy: 0.9772\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9924 - val_loss: 0.0570 - val_accuracy: 0.9796\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0370 - accuracy: 0.9892 - val_loss: 0.0554 - val_accuracy: 0.9804\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.0621 - val_accuracy: 0.9764\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.0585 - val_accuracy: 0.9772\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.0591 - val_accuracy: 0.9788\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0522 - val_accuracy: 0.9820\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.0548 - val_accuracy: 0.9792\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0580 - val_accuracy: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufu4tNuPL-h_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}